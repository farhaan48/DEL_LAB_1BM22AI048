{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfryXlFqsbgkXLgKvEQSUe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhaan48/DEL_LAB_1BM22AI048/blob/main/Lab6\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXjieH80NuTz",
        "outputId": "f6eb2220-02e2-4be7-9822-82ce42a46917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tangent Distance between sample 0 and 1: 10.994592666625977\n",
            "Tangent Propagation applied.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Adversarial Training\n",
        "def generate_adversarial_examples(model, X, y, epsilon=0.1):\n",
        "    X_var = tf.Variable(X, dtype=tf.float32)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(X_var)\n",
        "        pred = model(X_var)\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(y, pred)\n",
        "    gradients = tape.gradient(loss, X_var)\n",
        "    adversarial = X + epsilon * tf.sign(gradients)\n",
        "    return tf.clip_by_value(adversarial, 0, 1)\n",
        "\n",
        "# Tangent Distance\n",
        "def tangent_distance(x1, x2):\n",
        "    diffs = x1 - x2\n",
        "    return np.sqrt(np.sum(diffs**2))\n",
        "\n",
        "# Tangent Propagation\n",
        "def tangent_propagation(model, X, tangent_vectors, lambda_val=0.1):\n",
        "    tangent_vectors = tf.convert_to_tensor(tangent_vectors, dtype=tf.float32)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(X)\n",
        "        pred = model(X)\n",
        "        loss = lambda_val * tf.reduce_mean(tf.square(tf.matmul(tangent_vectors, tf.transpose(pred))))\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer = tf.optimizers.Adam()\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define a simple model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(28, 28)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Generate random data\n",
        "    X = np.random.rand(100, 28, 28).astype(np.float32)\n",
        "    y = np.random.randint(0, 10, size=100)\n",
        "\n",
        "    # Adversarial Training\n",
        "    adversarial_X = generate_adversarial_examples(model, X, y)\n",
        "\n",
        "    # Tangent Distance\n",
        "    distance = tangent_distance(X[0].flatten(), X[1].flatten())\n",
        "    print(f\"Tangent Distance between sample 0 and 1: {distance}\")\n",
        "\n",
        "    # Tangent Propagation\n",
        "    tangent_vectors = np.random.rand(10, 10).astype(np.float32)  # Adjusted shape\n",
        "    tangent_propagation(model, tf.convert_to_tensor(X, dtype=tf.float32), tangent_vectors)\n",
        "    print(\"Tangent Propagation applied.\")"
      ]
    }
  ]
}